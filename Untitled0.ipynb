{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxEW-g9t_2tS"
      },
      "source": [
        "from collections import defaultdict, Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class LanguageNgramModel:\n",
        "   \n",
        "    def __init__(self, order=1, smoothing=1.0, recursive=0.001):\n",
        "        self.order = order\n",
        "        self.smoothing = smoothing\n",
        "        self.recursive = recursive\n",
        "    \n",
        "    def fit(self, corpus):\n",
        "        \n",
        "        self.counter_ = defaultdict(lambda: Counter())\n",
        "        self.vocabulary_ = set()\n",
        "        for i, token in enumerate(corpus[self.order:]):\n",
        "            context = corpus[i:(i+self.order)]\n",
        "            self.counter_[context][token] += 1\n",
        "            self.vocabulary_.add(token)\n",
        "        self.vocabulary_ = sorted(list(self.vocabulary_))\n",
        "        if self.recursive > 0 and self.order > 0:\n",
        "            self.child_ = LanguageNgramModel(self.order-1, self.smoothing, self.recursive)\n",
        "            self.child_.fit(corpus)\n",
        "            \n",
        "    def get_counts(self, context):\n",
        "        \n",
        "        if self.order:\n",
        "            local = context[-self.order:]\n",
        "        else:\n",
        "            local = ''\n",
        "        freq_dict = self.counter_[local]\n",
        "        freq = pd.Series(index=self.vocabulary_)\n",
        "        for i, token in enumerate(self.vocabulary_):\n",
        "            freq[token] = freq_dict[token] + self.smoothing\n",
        "        if self.recursive > 0 and self.order > 0:\n",
        "            child_freq = self.child_.get_counts(context) * self.recursive\n",
        "            freq += child_freq\n",
        "        return freq\n",
        "    \n",
        "    def predict_proba(self, context):\n",
        "        \n",
        "        counts = self.get_counts(context)\n",
        "        return counts / counts.sum()\n",
        "    \n",
        "    def single_log_proba(self, context, continuation):\n",
        "       \n",
        "        result = 0.0\n",
        "        for token in continuation:\n",
        "            result += np.log(self.predict_proba(context)[token])\n",
        "            context += token\n",
        "        return result\n",
        "    \n",
        "    def single_proba(self, context, continuation):\n",
        "       \n",
        "        return np.exp(self.single_log_proba(context, continuation))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmZmHRu2B910"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq3vyHRIASoZ"
      },
      "source": [
        "class MissingLetterModel:\n",
        "    \n",
        "    def __init__(self, order=0, smoothing_missed=0.3, smoothing_total=1.0):\n",
        "        self.order = order\n",
        "        self.smoothing_missed = smoothing_missed\n",
        "        self.smoothing_total = smoothing_total\n",
        "    \n",
        "    def fit(self, sentence_pairs):\n",
        "      \n",
        "        self.missed_counter_ = defaultdict(lambda: Counter())\n",
        "        self.total_counter_ = defaultdict(lambda: Counter())\n",
        "        for (original, observed) in sentence_pairs:\n",
        "            for i, (original_letter, observed_letter) \\\n",
        "                    in enumerate(zip(original[self.order:], observed[self.order:])):\n",
        "                context = original[i:(i+self.order)]\n",
        "                if observed_letter == '-':\n",
        "                    self.missed_counter_[context][original_letter] += 1\n",
        "                self.total_counter_[context][original_letter] += 1 \n",
        "    \n",
        "    def predict_proba(self, context, last_letter):\n",
        "        \n",
        "        if self.order:\n",
        "            local = context[-self.order:]\n",
        "        else:\n",
        "            local = ''\n",
        "        missed_freq = self.missed_counter_[local][last_letter] + self.smoothing_missed\n",
        "        total_freq = self.total_counter_[local][last_letter] + self.smoothing_total\n",
        "        return missed_freq / total_freq\n",
        "    \n",
        "    def single_log_proba(self, context, continuation, actual=None):\n",
        "       \n",
        "        if not actual:\n",
        "            actual = continuation\n",
        "        result = 0.0\n",
        "        for orig_token, act_token in zip(continuation, actual):\n",
        "            pp = self.predict_proba(context, orig_token)\n",
        "            if act_token != '-':\n",
        "                pp = 1 - pp\n",
        "            result += np.log(pp)\n",
        "            context += orig_token\n",
        "        return result\n",
        "    \n",
        "    def single_proba(self, context, continuation, actual=None):\n",
        "        \n",
        "        return np.exp(self.single_log_proba(context, continuation, actual))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryt5LkAPApVN",
        "outputId": "ba7f74d2-20c6-4a84-d803-7f9888d66d6b"
      },
      "source": [
        "lang_model = LanguageNgramModel(1)\n",
        "lang_model.fit(' abracadabra ')\n",
        "print(lang_model.predict_proba(' bra'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     0.181777\n",
            "a    0.091297\n",
            "b    0.272529\n",
            "c    0.181686\n",
            "d    0.181686\n",
            "r    0.091025\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5f0AAuEAtlO",
        "outputId": "d8900c35-d61e-44bc-bc6e-2d479e359823"
      },
      "source": [
        "missed_model = MissingLetterModel(0)\n",
        "missed_model.fit([('abracadabra', 'abr-c-d-br-')]) \n",
        "\n",
        "print({letter: missed_model.predict_proba('abr', letter) for letter in 'abc'})"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'a': 0.7166666666666667, 'b': 0.09999999999999999, 'c': 0.15}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34edpVmgA4nN",
        "outputId": "a9d2c3cf-3210-45b7-b2d1-61dd2119a2e9"
      },
      "source": [
        "print(missed_model.single_proba('', 'abra', 'abr-'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.16447499999999998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrZjojjoA7OR",
        "outputId": "67386beb-6cea-4735-bbe7-0292df7412db"
      },
      "source": [
        "np.log10(27) * 10\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14.313637641589875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfyeYD91BA4Y",
        "outputId": "3c77f979-ca60-4418-cb9e-52322770deb7"
      },
      "source": [
        "from heapq import heappush, heappop\n",
        "\n",
        "def generate_options(prefix_proba, prefix, suffix, \n",
        "                     lang_model, missed_model, optimism=0.5, cache=None):\n",
        "    \"\"\" Generate partial options of abbreviation decoding (a helper function)\n",
        "    Parameters:\n",
        "        prefix_proba - log probability of decoded part of the abbreviation\n",
        "        prefix - decoded part of the abbreviation\n",
        "        suffix - not decoded part of the abbreviation\n",
        "        lang_model - the language model\n",
        "        missed_model - the abbreviation probability model\n",
        "        optimism - coefficient for log likelihood of the word end\n",
        "        cache - storage of suffix likelihood estimates\n",
        "    Returns: list of options in the form (likelihood estimate, decoded part, \n",
        "        not decoded part, the new letter, the suffix likelihood estimate)\n",
        "    \"\"\"\n",
        "    options = []\n",
        "    for letter in lang_model.vocabulary_ + ['']:\n",
        "        if letter:  # here we assume the character was missing\n",
        "            next_letter = letter\n",
        "            new_suffix = suffix\n",
        "            new_prefix = prefix + next_letter\n",
        "            proba_missing_state = - np.log(missed_model.predict_proba(prefix, letter))\n",
        "        else:  # here we assume there was no missing character\n",
        "            next_letter = suffix[0]\n",
        "            new_suffix = suffix[1:]\n",
        "            new_prefix = prefix + next_letter\n",
        "            proba_missing_state = - np.log((1 - missed_model.predict_proba(prefix, next_letter)))\n",
        "        proba_next_letter = - np.log(lang_model.single_proba(prefix, next_letter))\n",
        "        if cache:\n",
        "            proba_suffix = cache[len(new_suffix)] * optimism\n",
        "        else:\n",
        "            proba_suffix = - np.log(lang_model.single_proba(new_prefix, new_suffix)) * optimism\n",
        "        proba = prefix_proba + proba_next_letter + proba_missing_state + proba_suffix\n",
        "        options.append((proba, new_prefix, new_suffix, letter, proba_suffix))\n",
        "    return options\n",
        "\n",
        "print(generate_options(0, ' ', 'brac ', lang_model, missed_model))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(6.929663174828117, '  ', 'brac ', ' ', 3.7800651217336947), (5.042879645338754, ' a', 'brac ', 'a', 3.4572571306016755), (8.09487194753453, ' b', 'brac ', 'b', 3.846661605771999), (7.623807861705187, ' c', 'brac ', 'c', 3.7800651217336947), (7.623807861705187, ' d', 'brac ', 'd', 3.7800651217336947), (8.09487194753453, ' r', 'brac ', 'r', 3.846661605771999), (4.858238261775765, ' b', 'rac ', '', 2.8072524973494524)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dMu2Wi_BHbx"
      },
      "source": [
        "def noisy_channel(word, lang_model, missed_model, freedom=3.0, \n",
        "                  max_attempts=10000, optimism=0.9, verbose=False):\n",
        "    \"\"\" Suggest phrases, for which word may be the abbreviation \n",
        "    parameters:\n",
        "        word - string, the abbreviation\n",
        "        lang_model - the language model\n",
        "        missed_model - the abbreviation probability model\n",
        "        freedom - possible quality range of log likelihood of the candidates\n",
        "        max_attempts - maximum number of iterations\n",
        "        optimism - coefficient for log likelihood of the word end\n",
        "        verbose - whether to print current candidates in the runtime\n",
        "    returns: dict of keys - suggested phrases, and values - \n",
        "        minus log likelihood of candidates\n",
        "        The less this value, the more likely the suggestion\n",
        "    \"\"\"\n",
        "    query = word + ' '\n",
        "    prefix = ' '\n",
        "    prefix_proba = 0.0\n",
        "    suffix = query\n",
        "    full_origin_logprob = -lang_model.single_log_proba(prefix, query)\n",
        "    no_missing_logprob = -missed_model.single_log_proba(prefix, query)\n",
        "    best_logprob = full_origin_logprob + no_missing_logprob\n",
        "    # add an empty prefix to the heap\n",
        "    heap = [(best_logprob * optimism, prefix, suffix, '', best_logprob * optimism)]\n",
        "    # add the default candidate (without missing characters) \n",
        "    candidates = [(best_logprob, prefix + query, '', None, 0.0)]\n",
        "    if verbose:\n",
        "        print('baseline score is', best_logprob)\n",
        "    # prepare storage of the phrase suffix probabilities\n",
        "    cache = {}\n",
        "    for i in range(len(query)+1):\n",
        "        future_suffix = query[:i]\n",
        "        cache[len(future_suffix)] = -lang_model.single_log_proba('', future_suffix) # rough approximation\n",
        "        cache[len(future_suffix)] += -missed_model.single_log_proba('', future_suffix) # at least add missingness\n",
        "    \n",
        "    for i in range(max_attempts):\n",
        "        if not heap:\n",
        "            break\n",
        "        next_best = heappop(heap)\n",
        "        if verbose:\n",
        "            print(next_best)\n",
        "        if next_best[2] == '':  # the phrase is fully decoded\n",
        "            # if the phrase is good enough, add it to the answer\n",
        "            if next_best[0] <= best_logprob + freedom:\n",
        "                candidates.append(next_best)\n",
        "                # update estimate of the best likelihood\n",
        "                if next_best[0] < best_logprob:\n",
        "                    best_logprob = next_best[0]\n",
        "        else: # # the phrase is not fully decoded - generate more options\n",
        "            prefix_proba = next_best[0] - next_best[4] # all proba estimate minus suffix\n",
        "            prefix = next_best[1]\n",
        "            suffix = next_best[2]\n",
        "            new_options = generate_options(\n",
        "                prefix_proba, prefix, suffix, lang_model, \n",
        "                missed_model, optimism, cache)\n",
        "            # add only the solution potentioally no worse than the best + freedom\n",
        "            for new_option in new_options: \n",
        "                if new_option[0] < best_logprob + freedom:\n",
        "                    heappush(heap, new_option)\n",
        "    if verbose:\n",
        "        print('heap size is', len(heap), 'after', i, 'iterations')\n",
        "    result = {}\n",
        "    for candidate in candidates:\n",
        "        if candidate[0] <= best_logprob + freedom:\n",
        "            result[candidate[1][1:-1]] = candidate[0]\n",
        "    return result"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvPNVDhjBL91",
        "outputId": "ff3e201c-ac5c-4f19-8029-ef8c2214fab0"
      },
      "source": [
        "result = noisy_channel('brc', lang_model, missed_model, verbose=True, freedom=1)\n",
        "print(result)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "baseline score is 7.683183062275049\n",
            "(6.914864756047544, ' ', 'brc ', '', 6.914864756047544)\n",
            "(6.755450684372974, ' b', 'rc ', '', 4.704464919946662)\n",
            "(5.824911949460505, ' br', 'c ', '', 2.686363732552668)\n",
            "(7.088440394887126, ' brc', ' ', '', 1.7075575253192956)\n",
            "(7.139259830483152, ' bra', 'c ', 'a', 2.686363732552668)\n",
            "(7.68318306227505, ' brc ', '', '', -0.0)\n",
            "(8.028446927360166, ' brac', ' ', '', 1.7075575253192956)\n",
            "(8.362157608120238, ' a', 'brc ', 'a', 6.776535093383159)\n",
            "(7.695457216846014, ' ab', 'rc ', '', 4.704464919946662)\n",
            "(6.764918481933545, ' abr', 'c ', '', 2.686363732552668)\n",
            "(8.028446927360166, ' abrc', ' ', '', 1.7075575253192956)\n",
            "(8.079266362956194, ' abra', 'c ', 'a', 2.686363732552668)\n",
            "(8.62318959474809, ' abrc ', '', '', -0.0)\n",
            "(8.62318959474809, ' brac ', '', '', -0.0)\n",
            "(8.674062909624206, ' brca', ' ', 'a', 1.7075575253192956)\n",
            "heap size is 0 after 15 iterations\n",
            "{'brc': 7.68318306227505, 'abrc': 8.62318959474809, 'brac': 8.62318959474809}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uw27ED7tBPTW",
        "outputId": "48254a37-3fd1-4a04-bc84-e9be2a5a4046"
      },
      "source": [
        "import re\n",
        "\n",
        "with open('/content/The Fellowship Of The Ring.txt', encoding = 'ISO-8859-1') as f:\n",
        "    text = f.read()\n",
        "\n",
        "text2 = re.sub(r'[^a-z ]+', '', text.lower().replace('\\n', ' '))\n",
        "all_letters = ''.join(list(sorted(list(set(text2)))))\n",
        "print(repr(all_letters)) \n",
        "\n",
        "missing_set =  (\n",
        "    [(all_letters, '-' * len(all_letters))] * 3 \n",
        "    + [(all_letters, all_letters)] * 10\n",
        "    + [('aeiouy', '------')] * 30 \n",
        ")\n",
        "\n",
        "big_lang_m = LanguageNgramModel(order=4, smoothing=0.001, recursive=0.01)\n",
        "big_lang_m.fit(text2)\n",
        "big_err_m = MissingLetterModel(order=0, smoothing_missed=0.1)\n",
        "big_err_m.fit(missing_set)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "' abcdefghijklmnopqrstuvwxyz'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPQO4n7vBV-f",
        "outputId": "5af033eb-e8c1-46ea-85e2-96529b313474"
      },
      "source": [
        "for i in range(5):\n",
        "    tmp = LanguageNgramModel(i, 0.001, 0.01)\n",
        "    tmp.fit(text2[0:-5000])\n",
        "    print(i, tmp.single_log_proba(' ', text2[-5000:]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 -13842.824833511095\n",
            "1 -11552.532955893628\n",
            "2 -8998.75842752694\n",
            "3 -7291.087350571061\n",
            "4 -6470.896511925662\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hztw9fQ8BaMa",
        "outputId": "fbb5ec86-0e6f-49d9-8042-f87f99b44504"
      },
      "source": [
        "noisy_channel('sm', big_lang_m, big_err_m)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sam': 7.431491285816195, 'same': 9.59681958532011, 'some': 7.776754906910593}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dy2r0RXWBcqe",
        "outputId": "17b31070-b60b-4f64-f3ac-fe611d30ddc4"
      },
      "source": [
        "noisy_channel('frd', big_lang_m, big_err_m)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'frodo': 6.978234962097816}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmPZxYBOBgMy",
        "outputId": "5e94a3d0-7747-41fc-9a1b-0521e6a2e728"
      },
      "source": [
        "noisy_channel('rng', big_lang_m, big_err_m)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ring': 7.714350422234351}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzzKigk_Bi3T",
        "outputId": "4293cb47-5824-41e1-b316-a6bda4094240"
      },
      "source": [
        "noisy_channel('wtr', big_lang_m, big_err_m)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'water': 8.7362114655837}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si-1_r3sBlyx",
        "outputId": "072214c3-27e8-4924-b3e3-5a0302524b9d"
      },
      "source": [
        "noisy_channel('btl', big_lang_m, big_err_m)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'battle': 12.7082226232641,\n",
              " 'bottle': 13.420487477567903,\n",
              " 'but all': 14.755800315166107,\n",
              " 'but ill': 15.47669528673228}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NICNY4XXBoCW",
        "outputId": "faa6c665-157d-4cf3-977c-1fb947e207a6"
      },
      "source": [
        "noisy_channel('batlhrse', big_lang_m, big_err_m)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'battle horse': 25.281337462245297, 'battle horses': 27.491807186983152}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW4w9s1-BqR0",
        "outputId": "897aecbc-27d5-48ac-d33e-e73f77882bfe"
      },
      "source": [
        "noisy_channel('wtrbtl', big_lang_m, big_err_m)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'water battle': 23.841372876212038,\n",
              " 'water bottle': 24.033348730553502,\n",
              " 'water but all': 24.514714340135438,\n",
              " 'water but ill': 25.235609311701612,\n",
              " 'water but lay': 25.670984688831936,\n",
              " 'water but lie': 26.699689281350206}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B8Idzm8BtLq",
        "outputId": "966af55e-0544-4348-a73e-96ecfaed3169"
      },
      "source": [
        "print(noisy_channel('bsktball', big_lang_m, big_err_m, freedom=5))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'bsktball': 33.29238221032431, 'basket ball': 34.05472659461263}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzBoWa8DBvwD",
        "outputId": "2399bb2f-4a44-4b2d-9942-875efee70a74"
      },
      "source": [
        "print(noisy_channel('bwlingbl', big_lang_m, big_err_m, freedom=5))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'bwling blue': 31.412565922830485, 'bwling bilbo': 30.789436931566357, 'bwling ble': 34.583916537577785, 'bwling blin': 34.99982563357195, 'bwling black': 32.07397342527013, 'bwling blow': 33.24415445359094, 'bewilling blue': 31.026438289279493, 'bewilling bilbo': 30.403309298015365, 'bewilling ble': 34.197788904026794, 'bewilling blin': 34.61369800002096, 'bewilling black': 31.68784579171914, 'bewilling blow': 32.858026820039946, 'bewilling bill': 32.245136200786355, 'bewilling below': 32.28376086042576, 'bwling bill': 32.63126383433735, 'bewilling belia': 32.638791094399096, 'bwling below': 32.66988849397675, 'bwling belia': 33.02491872795009, 'bwling belt': 33.29729591439916, 'bwling bling': 33.491281179564, 'bwling bell': 34.2749747573314, 'bowling blue': 30.77618032619044, 'bowling bilbo': 30.15305133492631, 'bowling ble': 33.94753094093774, 'bowling blin': 34.363440036931905, 'bowling black': 31.437587828630086, 'bowling blow': 32.60776885695089, 'bowling bill': 31.9948782376973, 'bowling bl': 35.05745619477569, 'bowling below': 32.0335028973367, 'bowling blad': 35.092358451711355, 'bowling belia': 32.38853313131004, 'bwling blind': 35.09644117391327}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrPoetlQBx6A",
        "outputId": "d52f5b66-b7a5-43c0-a7d8-e308ebd24506"
      },
      "source": [
        "part = text[10502:11149]\n",
        "result = ''\n",
        "for i, letter in enumerate(part):\n",
        "    if np.random.rand() * 0.5 < big_err_m.single_proba(part[0:i], letter):\n",
        "        result += letter\n",
        "print(result)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PROLOGUE\n",
            "\n",
            "Ths bok s lrgel concrnd wth Hobbts, nd from its pags  radr may dscvr mch of ther chractr and  little of thr hstor. Frthr informaton will ls be fnd n the selection from the Rd Book f Wstmrch that has alrad ben pblshd, ndr th ttl of _The Hbbit_. That stry ws derived from th rlir chapters of the Red Bk, cmposed b Bilb himself, th first Hbbt to become famous in th wrld at lrge, nd calld by hm _Thr and Back Agan,_ snc th tld f hs journe nt th Est nd his return: n dvnture whch later nvlved ll th Hobbts n th grt events of tht Age that are\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqHZgAzuB0GS",
        "outputId": "60b9ad0f-d589-4327-e0e5-618dfeacffb1"
      },
      "source": [
        "np.random.seed(20)\n",
        "text = \"Frodo\"\n",
        "for i in range(300):\n",
        "    proba = big_lang_m.predict_proba(text)\n",
        "    text += np.random.choice(proba.index, size=1, p=proba)[0]\n",
        "print(text+'.')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Frodo would me but them asked his is far and soft pass then sping and leasant the ring feeline stair were in our healins thats bentfully shrooms at the shire oppose if you woulder the whence and up there was raged or tiding in this sing twre dismayed he frodo from the work the will the ears what all grow.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}